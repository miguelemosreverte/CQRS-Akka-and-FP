<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Welcome file</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="diagram-of-a-cat-jump">Diagram of a cat jump</h1>
<p>During the years, the cat jump reflex was a phenomena that intrigued the population. They always fell on their feet.<br>
This is <strong>the oldest recording we have of such phenomena</strong>, captured in 1894.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/7/7f/Falling_cat_1894.jpg" alt="enter image description here"></p>
<p>In this project, we are going to make the equivalent of a <strong>cat jump</strong>.<br>
That is, we are going to implement an arquitecture using OOP, for then pivot to FP.</p>
<p>Let’s hope that we land on our feet.</p>
<h1 id="the-architecture">1 - The Architecture</h1>
<p>This is a CQRS diagram, summarized by text:</p>
<ol>
<li>Data comes in</li>
<li>We split the data into it’s most atomic expressions
<ul>
<li>using DomainDrivenDesign as a guide:
<ul>
<li>we are looking for <em>value objects</em>, and <em>entities</em></li>
</ul>
</li>
</ul>
</li>
<li>It is routed to processors [writeside]
<ul>
<li>this processors are stateful and recover from failure</li>
<li>this processors use Event Sourcing to recover from failure</li>
</ul>
</li>
<li>We react to this events to create an aggregation (ie.: the sum, the average)
<ul>
<li>using DomainDrivenDesign as a guide:
<ul>
<li>now we are looking for <em>aggregates</em></li>
</ul>
</li>
</ul>
</li>
<li>We store this aggregations to a query-friendly database [readside]</li>
</ol>
<p>Now this is the same, but as a painting.<br>
<img src="https://i.imgur.com/WgEohXU.png" alt="enter image description here"></p>
<p>This architecture can be implemented in many ways, no need to couple to any paradigm or framework to do so. After all, it was invented a while ago. Not in 1894 as in the photo of the jumping cat, mind you, but very old and known in terms of CS history.</p>
<blockquote></blockquote>
<pre><code>CQRS was invented when performance was an issue, (still is), and to avoid system overload the entire system was split into two: The writeside, were the most transactional bussiness logic was placed, and then the conclusions, which could take their time to be computed, as it ussually did at the time. (And for some reason, as of 2020, still does).
It is true that even though computers have gotten stronger with the passage of time, our hunger for conclusions has all but decreased. 
Software, someone wiser once said, expands like gas to fill any container, no matter the size. And because of this principle is that we are still talking about CQRS on 2020. Because of performance.
</code></pre>
<p>CQRS means to not block the input of data, to let it come in without throttle. Because it will be <em>then</em> when we will aggregate it’s values to achieve a conclusion.</p>
<p>Until then fullfill those transactions as fast as you can!<br>
<em>Don’t let anyone block you!</em></p>
<p>That is, if I can be concise about it, my definition for CQRS.</p>
<p>Now, let’s cut the talk and let’s talk bussiness.</p>
<h1 id="the-bussiness">2- The Bussiness</h1>
<p>Our domain is going to be about the GDP of countries. How much they earn yearwise.</p>
<p>To do this we are going to have:</p>
<ol>
<li>Entities
<ul>
<li>Country</li>
</ul>
</li>
<li>Value Objects
<ul>
<li>GDP</li>
</ul>
</li>
</ol>
<p>We are going to rank them, this is an aggregation.</p>
<ol start="3">
<li>Aggregates
<ul>
<li>TopTenCountries</li>
</ul>
</li>
</ol>
<p>The top ten countries is an aggregation where we sort the countries by GDP and take the first ten.<br>
It is a conclusion, as such it will be decoupled from the ingestion, which is the writeside. We are going to do it later, on the readside.</p>
<p>It will be eventually consistent with the input, meaning that it may take a while to achieve full consistency with the input from writeside, but it will get there. <em>Eventually</em>.</p>
<p>We can make a drawing out if this. Let’s see.<br>
<img src="https://i.imgur.com/Ovcm69z.png" alt="enter image description here"></p>
<h2 id="domaindrivendesign">2.1 DomainDrivenDesign</h2>
<p>2.1.1<br>
We can start by modeling Domain Driven Design itself!<br>
<img src="https://i.imgur.com/Taujpey.png" alt="enter image description here"></p>
<p>Now that we have these useful guidelines, we can continue to make a little proof of concept on the test folder:<br>
<img src="https://i.imgur.com/9CtoI0E.png" alt="enter image description here"></p>
<p>2.1.2 Domain services<br>
We just went through with the DomainDrivenDesign building blocks, now we can use another abstraction proposed by DDD, services.</p>
<p>Our domain would need a service that given N countries with their GDP, would rank them and take the first ten.</p>
<p>Let’s apply some TDD.<br>
<img src="https://i.imgur.com/CdUQihX.png" alt="enter image description here"><br>
<img src="https://i.imgur.com/qf3n5XQ.png" alt="enter image description here"></p>
<p>2.1.3 State, Commands, and Events<br>
A <strong>Command</strong> comes to our system, it wants to have consecuences.<br>
It wants to leave a fingerprint on your codebase and your database.<br>
But <strong>Command</strong> is, in fact, a <em>suggestion</em>. We could start calling them <strong>Suggestion</strong>, because <em>what is most important about them</em> is that they can be rejected.<br>
An <strong>Event</strong> is <strong>Command</strong> we did not reject, its consecuence.<br>
We will persist events, make them the cornerstone of our resilience:<br>
as with EventSourcing we can recreate the entire state of our application in case of failure. Our system crashes? No problem. Let it crash. We will recover our state, and we will do so by iterating over every event we stored.<br>
The foundations of our model, the <strong>Event</strong>.<br>
And a State, given an Event, will change. Simple as that.</p>
<p>I got a small citation from a great author on this topic.<br>
Citing Greg Young.</p>
<blockquote>
<p>One way commands dont exist.<br>
Commands can be rejected, or they are valid<br>
and become Events.<br>
… If one way commands existed you could<br>
extract money from an ATM, just by asking<br>
for it. And only after the fact would the ATM<br>
know that your bank account had no funds,<br>
and then, what then! It would grow a pair<br>
of legs and chase you over the street.</p>
</blockquote>
<p><img src="https://i.imgur.com/bNk70su.png" alt="enter image description here"><br>
Our application, implemented:<br>
<img src="https://i.imgur.com/Dz7QlMG.png" alt="enter image description here"></p>
<h1 id="infrastructure">3. Infrastructure:</h1>
<h2 id="actor-model">3.1 Actor Model</h2>
<p>3.1.1<br>
<strong>DomainDrivenDesign</strong> and the <strong>Actor Model</strong> just click.</p>
<p>See the State we did just there? Its going to become the immutable data structure that our Actor is going to be in charge of. The actor is going to constantly mutate, but it will do so responsibly, by doing one assignment.<br>
<em>The state assignment.</em><br>
<img src="https://i.imgur.com/KSoi06X.png" alt="enter image description here"></p>
<p>3.1.2<br>
Now we can introduce the concept of <strong>sharding</strong>.</p>
<p>The Actor Model is about distributed computing, and as such the actors can live on different computers but still be able to communicate among each other.</p>
<p>The computers we call them <strong>shards</strong>, and <strong>sharding</strong> is the act of distributing actors evenly across <strong>shards</strong>, where you, the developer, can work as if they were all located on the same computer. There is no need for you to worry about networking, you can just send the message and Akka will handle the rest.</p>
<p>3.1.3 Sharded Actors<br>
Let’s test our luck implementing a trait called <strong>ShardedEntity</strong>, which is going to become responsible of the boilerplate that takes to create a sharded actor.</p>
<p><img src="https://i.imgur.com/InYC5mJ.png" alt="enter image description here"><br>
Note that we had to make a compromise:<br>
In order to get us a sharded actor, now our messages would have an <strong>entityId</strong> and a <strong>shardId</strong>.</p>
<p>However, again with the same <em>builder</em>, <em>boilerplate remover by inheritance</em> we did before, we can sort this out and forget about it.<br>
<img src="https://i.imgur.com/gTV6s8o.png" alt="enter image description here"><br>
<img src="https://i.imgur.com/ChsTTO2.png" alt="enter image description here"><br>
All we have to do now is make some tests, see them run green, and start working on the infrastructure components, such as the Kafka consumer which we are going to use.</p>
<h2 id="pubsub">3.2 PubSub</h2>
<p>Okay, now we can venture into one of the last key pieces of an Akka project, the communication layer against the outside world.</p>
<p>Kafka Transactions provide <strong>exactly-once-delivery</strong> guarantees, which means that not only is Kafka going to try over and over again to send us the messages if the fail to answer, but there is also the guarantee that we are not going to receive the same message twice.</p>
<p>3.2.1 The algebra<br>
So we are going to start by making a few reasonable abstractions, such as <strong>MessageProducer</strong> and <strong>MessageProcessor</strong>, which we are going to implement in both Production and Mock environments.</p>
<p>The idea is to avoid giving <em>too much</em> responsability for what should be a simple infrastructure module.<br>
Thus, we are going to opt for delegating serialization/deserialization to the final user, and offer to publish and read the messages as they come and go over the network. And while it is true that over the network the messages are just array of bytes, there is something familiar about Strings that does not add overhead but makes our code look a little more practical to use.</p>
<p>3.2.2 The interpreter<br>
For production we mentioned we are going to use Kafka Transactions.<br>
We are going to take care when publishing that the messages are partitioned so that there is a 1 to 1 relationship between the Kafka partitions and the Akka shardings.<br>
This means that if we do everything right, every message will land on the node it will be processed.</p>
<p>We do this by literally sharing the hashing function between Kafka and Akka, for partitioning and sharding, respectively.</p>
<p>I am going to make a diagram to explain the situation we are solving:<br>
<img src="https://i.imgur.com/AzTuTnM.png" alt="enter image description here"><br>
<img src="https://i.imgur.com/kX9BnmZ.png" alt="enter image description here"></p>
<h2 id="how-to-connect-writeside-and-readside">3.3 How to connect Writeside and Readside</h2>
<h3 id="the-lightbend-proposal">3.3.1 The Lightbend Proposal</h3>
<p>Use Cassandra materialized views to sort your events by tags, and Akka Persistence Query so stream them securely to your projections/http servers.</p>
<p>Here is my response, <strong>to Lightbend</strong>.<br>
<img src="https://i.imgflip.com/4fooj4.jpg" alt="enter image description here"></p>
<p>Not only have materialized views been pushed back to the experimental stage by Cassandra because of performance reasons.<br>
But Scylla, the trending Cassandra made using C++, which does run 10X faster thanks to a non blocking architecture and avoidance of garbage collection pauses <strong>does not support them</strong>, either. And for a reason, which is, once more, performance.</p>
<h3 id="es-is-the-main-bottleneck-of-any-reactive-app">3.3.2 ES is the main bottleneck of any reactive app</h3>
<p>You heard that right. Before you think about tuning your app, or even phantom the idea that Kafka may be the problem, know that unless you run a relation of 200% the nodes you have for processing for EventSourcing, you are missing out. That is that if you have 3 akka nodes you ought to have +6 Cassandra nodes. Maybe with Scylla the ratio would decrease, but the idea remains, that ES is the main bottleneck of any reactive app.</p>
<p>Generalized, this becomes a known truth about microservices in general, and that is that transactions against the databases are ussually the biggest impediment for performance.</p>
<p>Generalized two fold, this becomes the most known truth in software.<br>
That is that IO is always the bottleneck. File IO? Bad. Network IO? Worse.</p>
<p>So as a general rule of thumb, embrace your processor as much as you can and don’t let go, if you care about optimization.</p>
<h3 id="section">3.3.3</h3>
<p><strong>So. Lightbend proposes to use Cassandra for communication between writeside and readside</strong><br>
They are wrong. Plain and simple.<br>
I will play devil’s advocate for a moment here.<br>
Let’s say you care most for the consistency of your data than of performance.<br>
Then it becomes apparent that using a DB is much safer than using, say, a message queue, like Kafka. Kafka will destroy your messages in three hours without notice! What if Kafka fails! Your messages will get lost inflight!</p>
<p>Well, to that I have two answers, and will leave the reader to ponder if my answer suffices.</p>
<p>Kafka will destroy the messages in three hours without notice.</p>
<ul>
<li>Yes. It will. By then I will have processed that message, along with a thousands more.</li>
</ul>
<p>Kafka can fail! Your messages… they will be lost inflight!<br>
Look, if Kafka fails, the least you are going to be worried about is about a few messages lost. <strong>Because your whole system will be down</strong>. You will be getting phone calls that a major earthquake has awoken Godzilla who is eating voltage right now out of the AWS us-east-2 servers located in Oregon. Believe me, if Kafka fails, not only you will have a bigger problem in your hands, but also if it does fail, I have to branches for you to explore, and I presume them to be excluyent of any other. I do not think there to be any other two possible situations you would have to go through this scenario.</p>
<p>First branch, first situation you can be in:</p>
<ul>
<li>The messages you lost came from HTTP requests, so… they are definitely lost.<br>
My answer to this is that if they came from HTTP requests… they were not so critical after all.</li>
</ul>
<p>Second branch, second situation you can be in:</p>
<ul>
<li>The messages came from a queriable source of truth. A database. The database which had hooks which feed to Kafka. Picture yourself the CDC pattern, a’la Confluence DEBEZIUM.<br>
Okay then… great! Nothing of value was lost! Because we just have to rollback a few transactions, and start over from where we left.</li>
</ul>
<p>See? In conclusion, there is never an excuse for using the ES database as a communication tool. What to do?</p>
<h3 id="section-1">3.3.4</h3>
<p><strong>Avoid Lightbend advice. Use a  battle tested proposal</strong><br>
Use a purposely made message broker for inter process communication.<br>
Which by the way, they have gotten better with the years, and now have <strong>exactly once delivery guarantees</strong>, unless you pull the plug. In which case, sure, problems happen, but as we revised just before, we can confront them and say, “You are not going to make my application run like a snail!”</p>
<p>This is the veteran solution, the better solution. Has aged well, be LinkedIn thanked, for it is now not what it was before, as I hope this to be true for all of us. Let time improve our faults. Cheers.</p>
<p><img src="https://i.imgur.com/Ou6Ka5R.png" alt="enter image description here"><br>
<em>* who knew Die Verwandlung would be not about a man made croach, but in time, to be that of it’s writer made name of a technological marble, of an octopus of information who its influence would rival in pervasive potential with that of the author works themselves.</em><br>
<a href="https://soundcloud.com/migue-lemos/kafka-load-test-movement-i">https://soundcloud.com/migue-lemos/kafka-load-test-movement-i</a></p>
<h3 id="kafka-connector.-lightbend-or-typesafe">3.4 Kafka connector. Lightbend or Typesafe?</h3>
<p>By this point, I have an implementation of the Akka connector for Kafka, Alpakka, which is very <strong>OOP</strong>.<br>
As said, we had <em>traits</em> to obey, which were tighly coupled to Akka: A MessageProcessor ought to return a Future[akka.Done].<br>
To make matters worse, they were tighly coupled to the Future monad.</p>
<p>In short, very standard, by the book <strong>OOP</strong> . And while it sounds like I am throwing an entire paradigm under the bus here, bear with me, I have worked with <strong>OOP</strong> engineers who did not pause for a moment to ask for a more general signature. Are there <strong>OOP</strong> engineers who would have made such a claim? Do they exist? My personal experience is that they are much more focused around making <strong>DI</strong> work for <em>unit</em> and <em>acceptance</em> tests but to stop for a minute and think in more general, broader terms.<br>
Count me in on this bunch, still. There is a reason why this is a <strong>cat jump</strong>. I had not stopped to think, either.</p>
<p>Now, let’s see what the <strong>FP</strong> community has to say about this.<br>
The following code <em>is norm</em> among <strong>FP</strong> engineers.</p>
<pre class=" language-scala"><code class="prism  language-scala"><span class="token keyword">type</span> Topic <span class="token operator">=</span> <span class="token builtin">String</span>
<span class="token keyword">type</span> MessageProcessor<span class="token punctuation">[</span>O<span class="token punctuation">,</span> AlgorithmOutput<span class="token punctuation">]</span> <span class="token operator">=</span>
 Topic <span class="token keyword">=&gt;</span> Algorithm<span class="token punctuation">[</span>AlgorithmOutput<span class="token punctuation">]</span> <span class="token keyword">=&gt;</span> O
</code></pre>
<p>where <code>AlgorithmOutput</code> may be <code>Future[Done]</code> or <code>Unit</code>.<br>
This type parametrization used on this level is considered extreme by most <strong>OOP</strong> devs, and norm by most <strong>FP</strong> devs.</p>
<h4 id="lets-leave-both-implementations-but-avoid-using-inheritance-and-sub-type-polymorphism">3.4.1 Let’s leave both implementations, but avoid using inheritance and sub-type polymorphism</h4>
<p>We are going to make a signature like the one proposed above, and we will just have functions that complement it with either library.</p>
<p>Let’s start by taking KafkaMessageProcessor, which is a class that extends the MessageProcessor trait, and change it to be a function that given the necessary requirements, namely the ActorSystem, get’s us a MessageProcessor.</p>
<p><img src="https://i.imgur.com/QwiWfJX.png" alt="enter image description here"><br>
The signature alone tells us that it is indeed going to be coupled to Futures and Futures of akka.Done, specifically, but that it’s okay for this to be case, because, after all, what’s to expect? This is the alpakkaMessageProcessor!</p>
<p>The good thing is that now we don’t have to make a unit test version of the alpakkaMessageProcessor. There is no need! As long as we have a function that suffices the MessageProcessor signature, we are good.<br>
It’s liskov substitution and single responsability principles taken to the max: We can replace this function with <em>any other</em> implementation of the MessageProcessor signature, and it would work!<br>
So much boilerplate and naming avoided in one swift brush of paradigm change.</p>
</div>
</body>

</html>
